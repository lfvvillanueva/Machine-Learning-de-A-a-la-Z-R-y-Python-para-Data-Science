{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explicación de la Regresión Lineal Simple\n",
    "\n",
    "La regresión lineal simple es un método estadístico que permite modelar la relación lineal entre dos variables. Se utiliza ampliamente en análisis predictivos y en ciencia de datos para entender cómo cambia una variable dependiente ($y$) con respecto a una variable independiente ($x$).\n",
    "\n",
    "## Matemática detrás de la Regresión Lineal Simple\n",
    "\n",
    "La ecuación de una regresión lineal simple es:\n",
    "\n",
    "$$ y = \\beta_0 + \\beta_1 \\cdot x + \\epsilon $$\n",
    "\n",
    "donde:\n",
    "- $y$ es la variable dependiente que queremos predecir o explicar.\n",
    "- $x$ es la variable independiente.\n",
    "- $\\beta_0$ es el intercepto de la línea.\n",
    "- $\\beta_1$ es la pendiente de la línea, que indica el cambio en $y$ por cada unidad de cambio en $x$.\n",
    "- $\\epsilon$ es el término de error que representa lo que el modelo no puede explicar.\n",
    "\n",
    "### Estimación de los Parámetros\n",
    "\n",
    "Los parámetros $\\beta_0$ y $\\beta_1$ se estiman minimizando la suma de los cuadrados de los residuos (diferencias entre los valores observados y los valores predichos). Esta técnica se llama método de los mínimos cuadrados ordinarios (OLS). Las fórmulas para los estimadores son:\n",
    "\n",
    "$$ \\beta_1 = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2} $$\n",
    "$$ \\beta_0 = \\bar{y} - \\beta_1 \\bar{x} $$\n",
    "\n",
    "donde $\\bar{x}$ y $\\bar{y}$ son los promedios de $x$ y $y$, respectivamente.\n",
    "\n",
    "## Implementación en Python\n",
    "\n",
    "### Sin Bibliotecas Específicas\n",
    "\n",
    "```python\n",
    "# Datos de ejemplo\n",
    "x = [1, 2, 3, 4, 5]\n",
    "y = [2, 4, 5, 4, 5]\n",
    "\n",
    "# Cálculo de las medias de x y y\n",
    "x_mean = sum(x) / len(x)\n",
    "y_mean = sum(y) / len(y)\n",
    "\n",
    "# Cálculo de beta_1 y beta_0\n",
    "numerator = sum((xi - x_mean) * (yi - y_mean) for xi, yi in zip(x, y))\n",
    "denominator = sum((xi - x_mean) ** 2 for xi in x)\n",
    "beta_1 = numerator / denominator\n",
    "beta_0 = y_mean - beta_1 * x_mean\n",
    "\n",
    "# Mostrar los coeficientes\n",
    "print(\"Intercepto:\", beta_0)\n",
    "print(\"Pendiente:\", beta_1)\n",
    "\n",
    "```\n",
    "### Con Bibliotecas Específicas (scikit-learn)\n",
    "\n",
    "```python\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Datos de ejemplo\n",
    "x = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n",
    "y = np.array([2, 4, 5, 4, 5])\n",
    "\n",
    "# Creación del modelo de regresión lineal\n",
    "model = LinearRegression()\n",
    "model.fit(x, y)\n",
    "\n",
    "# Coeficientes del modelo\n",
    "print(\"Intercepto:\", model.intercept_)\n",
    "print(\"Pendiente:\", model.coef_[0])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
